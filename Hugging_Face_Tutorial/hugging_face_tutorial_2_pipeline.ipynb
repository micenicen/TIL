{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 함수\n",
    "# 파이프라인 기능은 트랜스포머 라이브러리의 가장 높은 API이다. \n",
    "# 원시 텍스트에서 사용 가능한 예측으로 이동하는 모든 단계를 재그룹화한다.\n",
    "# pre-processing -> Model -> post-Processing\n",
    "# 컴퓨터 모델은 텍스트가 아닌 숫자를 입력받기를 원한다. 그리고 인간은 모델의 출력을 텍스트로 받는 것을 원한다. \n",
    "# 이러한 것을 파이프라인을 통해서 처리하게 된다. \n",
    "# 파이프 라인은 다음과 같은 기능들을 가진다. \n",
    "#\n",
    "#\n",
    "#\n",
    "# 태스크           설명                                                                 모달리티\n",
    "# 텍스트 분류      텍스트에 알맞은 레이블 붙이기                                        자연어 처리(NLP)\n",
    "pipeline(task=“sentiment-analysis”)\n",
    "# 텍스트 생성      주어진 문자열 입력과 이어지는 텍스트 생성하기                        자연어 처리(NLP)\n",
    "pipeline(task=“text-generation”)\n",
    "# 개체명 인식      문자열의 각 토큰마다 알맞은 레이블 붙이기 (인물, 조직, 장소 등등)    자연어 처리(NLP)\n",
    "pipeline(task=“ner”)\n",
    "# 질의응답         주어진 문맥과 질문에 따라 올바른 대답하기                            자연어 처리(NLP)\n",
    "pipeline(task=“question-answering”)\n",
    "# 빈칸 채우기      문자열의 빈칸에 알맞은 토큰 맞추기                                   자연어 처리(NLP)\n",
    "pipeline(task=“fill-mask”)\n",
    "# 요약             텍스트나 문서를 요약하기                                             자연어 처리(NLP)\n",
    "pipeline(task=“summarization”)\n",
    "# 번역             텍스트를 한 언어에서 다른 언어로 번역하기                            자연어 처리(NLP)\n",
    "pipeline(task=“translation”)\n",
    "# 이미지 분류      이미지에 알맞은 레이블 붙이기                                        컴퓨터 비전(CV)\n",
    "pipeline(task=“image-classification”)\n",
    "# 이미지 분할      이미지의 픽셀마다 레이블 붙이기(시맨틱, 파놉틱 및 인스턴스 분할 포함)컴퓨터 비전(CV)\n",
    "pipeline(task=“image-segmentation”)\n",
    "# 객체 탐지        이미지 속 객체의 경계 상자를 그리고 클래스를 예측하기                컴퓨터 비전(CV)\n",
    "pipeline(task=“object-detection”)\n",
    "# 오디오 분류      오디오 파일에 알맞은 레이블 붙이기                                   오디오\n",
    "pipeline(task=“audio-classification”)\n",
    "# 자동 음성 인식   오디오 파일 속 음성을 텍스트로 바꾸기                                오디오\n",
    "pipeline(task=“automatic-speech-recognition”)\n",
    "# 시각 질의응답    주어진 이미지와 질문에 대해 올바르게 대답하기                        멀티모달\n",
    "pipeline(task=“vqa”)\n",
    "# 문서 질의응답    주어진 문서와 질문에 대해 올바르게 대답하기                          멀티모달\n",
    "pipeline(task=“document-question-answering”)\n",
    "# 이미지 캡션달기  주어진 이미지의 캡션 생성하기                                        멀티모달\n",
    "pipeline(task=“image-to-text”)\n",
    "\n",
    "# 주의사항\n",
    "# 큰 규모의 데이터셋(특히 음성이나 비전)의 경우 모든 입력 데이터를 메모리에 로드하기 위해 리스트 대신 제너레이터 형식으로\n",
    "# 제공되어야 한다. https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines 에서 확인 가능하다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b4156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8371170163154602}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 긍정/부정 파이프라인\n",
    "# 예를 감정분석 파이프라인을 살펴보자. \n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier(\"I've veen waiting for a HuggingFace course my whole life.\")\n",
    "\n",
    "# 이 파이프라인은 주어진 입력에 대해 텍스트 분류를 수행하고 그것이 긍정적인지 부정적인지를 결정한다. \n",
    "# 신뢰도로는 83%의 신뢰도의 긍정 라벨을 부여했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03af82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8371170163154602},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995144605636597}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 긍정/부정 파이프라인\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier([\n",
    "    \"I've veen waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much\"\n",
    "])\n",
    "\n",
    "# 여러 텍스트를 동일한 파이프라인에 전달할 수 있으며 이는 일괄 처리되어 모델을 통해 전달된다. \n",
    "# 입력이 여러개가 존재하는 경우. 리스트를 통해 전달할 수 있다. \n",
    "# 출력은 입력 텍스트와 동일한 순서로 된 개별의 결과 목록이다. 여기서 두번째 신뢰도가 매우 높게 부정 라벨을 부여했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4818aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d80b531b2e45bd8683a2c243a83a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c1daa6806049358dd532219ebb92ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d935c807f843a4b54255d692035b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873b753461c5443aae188ce119def023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1eb12e57b94b29a1d8dc98ae9303b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82620fd38ce4167af1b202ebb50f1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'this is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8697090148925781, 0.09091891348361969, 0.03937210515141487]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 붙이기\n",
    "# 또는 원하는 라벨을 설정할 수 있다. \n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification')\n",
    "classifier(\n",
    "    \"this is a course about the Transformers library\",\n",
    "    candidate_labels = [\"education\",\"politics\",\"business\"]\n",
    ")\n",
    "# 라벨은 교육, 정치, 비즈니스 라벨을 따라 입력 텍스트를 분류하려고 한다. \n",
    "# 파이프라인은 위의 단어가 교육에 대한 텍스트임을 빠르게 분류하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194456ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"in this course, we will teach you how to use multiple languages for your first time as a programmer or project leader. We'll use the same programming language, but with the purpose of providing you with tools and tips to find the correct application in the\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 생성 파이프라인\n",
    "from transformers import pipeline\n",
    "\n",
    "generater = pipeline('text-generation')\n",
    "generater(\"in this course, we will teach you how to\")\n",
    "# 텍스트 생성 파이프라인은 주어진 프롬프트를 자동 완성한다.\n",
    "# 출력은 무작위로 생성되므로 주어진 프롬프트에서 생성기 개체를 호출할 때 마다 변경된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297a1c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dba52abfc39451693bca324e7ee06ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cbba95d8504b51af50e4f80e2e2386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73f08dd61834251b0ca54b4a3434dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755eba13c31245c383c404154abe7560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cd436920b94e87b67bd7cb466b42bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4c6359872d4437b27892bf8e4e197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course, we will teach you how to get into the science of the universe, and how to become part of the natural history of the universe'},\n",
       " {'generated_text': \"in this course, we will teach you how to use the app to bring you an idea, the user's need, and more!\\n\\n\\n\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파인튜닝된 모델 파이프라인\n",
    "# 현재까지 연결된 기본 모델에 대해 파이프라인 API를 사용했다. \n",
    "# 물론 이 작업에 대해 사전학습되거나 파인튜닝된 모델을 사용할 수도 있다. \n",
    "# 허깅페이스 모델허브에는 작업별로 사용 가능한 모델을 필터링 할 수 있다. \n",
    "# 위에서는 gpt2모델이 디폴트였지만 더 많은 모델을 사용하는 것도 가능하다. \n",
    "from transformers import pipeline\n",
    "\n",
    "generater = pipeline('text-generation', model=\"distilgpt2\")\n",
    "generater(\"in this course, we will teach you how to\",\n",
    "         max_length=30,\n",
    "          num_return_sequences=2\n",
    "         )\n",
    "# distilgpt2는 허깅페이스팀에서 만든 경량 gpt2이다. 특정 프롬프트에서 파이프라인을 적용할 때 생성된 텍스트 최대 길이나 반환하려는\n",
    "# 문장의 수와 같은 여러 인수를 지정하는 것이 가능하다. 위에서는 길이는 30, 반환하는 결과값을 2개로 부여했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121bb5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091fc4657215446e8f5b3cfc37a259eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546c3f3cf5734bf79d6de4772762fa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd8078ba4ee4209bc172cb487ddeb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8154fb7fb4d4cf6a8853089d629bfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10d1890214e45eb9f2143fed5feaf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1961977779865265,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052717983722687,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필 마스크\n",
    "# 문장에서 다음 단어를 추측하여 텍스트를 생성하는 것이 GPT-2의 사전 학습 목표였다. \n",
    "# fill mask 파이프라인은 마스크값을 추측하는 bert의 사전학습 목표였다. \n",
    "# 누락된 단어에 대해 가장 가능성이 높은 두 가지 값을 묻고 가능한 답변으로 수학적, 계산적 답변을 얻었다. \n",
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\",top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc6d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1c4af5f5524c828a6f75fe636e40b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53f4a1df9b54dca8219985fd4bdbdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff08a879aa2445d895184b9717cb594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d588f9ae1348cf9316a66987338cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9876925,\n",
       "  'word': 'sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.97336537,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9870432,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 분류\n",
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is sylvain and i work at Hugging Face in Brooklyn\")\n",
    "# 모델이 수행할 수 있는 또 다른 작업은 문장 전체가 아닌 문장의 각 단어를 분류하는 것이다. \n",
    "# 문장에서 사람, 조직, 위치와 같은 엔티티를 식별하는 작업이 명명된 엔터티 인식이다. \n",
    "# 여기서 모델은 입력텍스트 내에서 사람(sylvain),조직(Hugging Face), 위치(Brooklyn)를 정상적으로 찾아냈다. \n",
    "# grouped_entities=True의 의미는 파이프라인 그룹을 동일한 엔터티(Hugging과 Face를 같이 묶기 위해)에 연결된 단어로 만드는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ed8a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a750e81d067b4fbaa97e01df88788a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f6722563eb4114bf59feaa3aa96937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66a62974881402f8d45d3866b5c53bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df402647a2e5419f8a8ba5bc9a36c2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8fab1ce3364611bcf9b38cb5f11ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7076236009597778, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출적 질문 답변\n",
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question =\"Where do I work?\",\n",
    "    context = \"My name is sylvain and i work at Hugging Face in Brooklyn\"\n",
    ")\n",
    "# 컨텍스트와 질문을 제공하면 모델은 질문에 대한 답변이 포함된 컨텍스트에서 텍스트 범위를 식별한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbdb36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8751c1a5640244bebfc9afb228e3df94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20386857f61e486a8bcd4249c17c993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dae7fb02e6b4edfb3e12e644ab24961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503408c80ff74b2b842a371fa6638095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b57bf0980344b7867417f40ad13144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The historic 4-3 ruling by the Colorado Supreme Court is likely to be taken up by the U.S. Supreme Court . It makes Trump the first presidential candidate deemed ineligible for the White House under a rarely used constitutional provision that bars officials who have engaged in \"insurrection or rebellion\" from holding office .'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기사 요약\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\"\"\"\n",
    "    Former President Donald Trump is disqualified from serving as U.S. president and cannot appear on the \n",
    "    primary ballot in Colorado because of his role in the Jan. 6, 2021, attack on the U.S. Capitol by his supporters, \n",
    "    the state's top court ruled Tuesday. The historic 4-3 ruling by the Colorado Supreme Court, \n",
    "    likely to be taken up by the U.S. Supreme Court, makes Trump the first presidential candidate deemed ineligible for \n",
    "    the White House under a rarely used constitutional provision that bars officials who have engaged in \"insurrection or \n",
    "    rebellion\" from holding office.\n",
    "\"\"\")\n",
    "\n",
    "# 요약 파이프라인을 통해 뉴스 기사요약도 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ebf8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c2ae6820ac45c2a2bafe4ac48d4b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe0c0118d7f4a63b5680fb5badef3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca39d7b0f43241598cf852f1e145fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a694de65444e09a177ee1607776cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef1fa5986c349ca9717ea125887c11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6f02adf7934db382be6335c3ba46ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edd15270032487aa3a881e466866f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 번역\n",
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face\")\n",
    "# 허깅페이스는 번역을 지원한다. \n",
    "# 프랑스어를 입력하고 영어를 출력받았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dabc940",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Couldn't reach https://www.dropbox.com/s/e2us0hcs3ilr20e/MInDS-14.zip?dl=1 (error 429)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Audio\n\u001b[1;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolyAI/minds14\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko-KR\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# 데이터셋 접속에 문제가 있음. \u001b[39;00m\n\u001b[0;32m      7\u001b[0m speech_recognizer \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautomatic-speech-recognition\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/wav2vec2-base-960h\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 파이프라인은 데이터셋을 전부 순회할 수 있다. 데이터셋을 로드하였으며 facebook의 wav2vec2-base-960h을 사용했다.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2152\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   2149\u001b[0m try_from_hf_gcs \u001b[38;5;241m=\u001b[39m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 2152\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39mdownload_and_prepare(\n\u001b[0;32m   2153\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2154\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2155\u001b[0m     verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[0;32m   2156\u001b[0m     try_from_hf_gcs\u001b[38;5;241m=\u001b[39mtry_from_hf_gcs,\n\u001b[0;32m   2157\u001b[0m     num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[0;32m   2158\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2159\u001b[0m )\n\u001b[0;32m   2161\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   2162\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2163\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   2164\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:948\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[0;32m    949\u001b[0m         dl_manager\u001b[38;5;241m=\u001b[39mdl_manager,\n\u001b[0;32m    950\u001b[0m         verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_split_kwargs,\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[0;32m    953\u001b[0m     )\n\u001b[0;32m    954\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1711\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1711\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[0;32m   1712\u001b[0m         dl_manager,\n\u001b[0;32m   1713\u001b[0m         verification_mode,\n\u001b[0;32m   1714\u001b[0m         check_duplicate_keys\u001b[38;5;241m=\u001b[39mverification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS\n\u001b[0;32m   1715\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS,\n\u001b[0;32m   1716\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs,\n\u001b[0;32m   1717\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1021\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[0;32m   1020\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[1;32m-> 1021\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_generators(dl_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msplit_generators_kwargs)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\PolyAI--minds14\\65c7e0f3be79e18a6ffaf879a083daf706312d421ac90d25718459cbf3c42696\\minds14.py:132\u001b[0m, in \u001b[0;36mMinds14._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_generators\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager):\n\u001b[0;32m    126\u001b[0m     langs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    127\u001b[0m         _ALL_CONFIGS\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m    130\u001b[0m     )\n\u001b[1;32m--> 132\u001b[0m     archive_path \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownload_and_extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_url)\n\u001b[0;32m    133\u001b[0m     audio_path \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mextract(\n\u001b[0;32m    134\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(archive_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMInDS-14\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     text_path \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mextract(\n\u001b[0;32m    137\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(archive_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMInDS-14\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:561\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload(url_or_urls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:424\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    421\u001b[0m download_func \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[0;32m    423\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 424\u001b[0m downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m map_nested(\n\u001b[0;32m    425\u001b[0m     download_func,\n\u001b[0;32m    426\u001b[0m     url_or_urls,\n\u001b[0;32m    427\u001b[0m     map_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    428\u001b[0m     num_proc\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mnum_proc,\n\u001b[0;32m    429\u001b[0m     disable_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m is_progress_bar_enabled(),\n\u001b[0;32m    430\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading data files\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    431\u001b[0m )\n\u001b[0;32m    432\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    433\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:456\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# Singleton\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    458\u001b[0m disable_tqdm \u001b[38;5;241m=\u001b[39m disable_tqdm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled()\n\u001b[0;32m    459\u001b[0m iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_struct\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m data_struct\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:450\u001b[0m, in \u001b[0;36mDownloadManager._download\u001b[1;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[0;32m    449\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached_path(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(url_or_filename)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m get_from_cache(\n\u001b[0;32m    183\u001b[0m         url_or_filename,\n\u001b[0;32m    184\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    185\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mforce_download,\n\u001b[0;32m    186\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[0;32m    187\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mresume_download,\n\u001b[0;32m    188\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39muser_agent,\n\u001b[0;32m    189\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mlocal_files_only,\n\u001b[0;32m    190\u001b[0m         use_etag\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39muse_etag,\n\u001b[0;32m    191\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    192\u001b[0m         token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m    193\u001b[0m         ignore_url_params\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mignore_url_params,\n\u001b[0;32m    194\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    195\u001b[0m         download_desc\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mdownload_desc,\n\u001b[0;32m    196\u001b[0m     )\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:601\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(head_error)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mConnectionError\u001b[0m: Couldn't reach https://www.dropbox.com/s/e2us0hcs3ilr20e/MInDS-14.zip?dl=1 (error 429)"
     ]
    }
   ],
   "source": [
    "# 자동음성인식\n",
    "# 일반적으로 open ai의 whisper가 많이 쓰인다. \n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"ko-KR\", split=\"train\") # 데이터셋 접속에 문제가 있음. \n",
    "#\n",
    "#\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n",
    "# 파이프라인은 데이터셋을 전부 순회할 수 있다. 데이터셋을 로드하였으며 facebook의 wav2vec2-base-960h을 사용했다.\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n",
    "# 훈련당시의 샘플링 레이트와 일치하는지 확인한다. \n",
    "\n",
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 다루기\n",
    "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/training_loop.ipynb#scrollTo=QV36iFzWCyY7\n",
    "# 이 사이트에서 확인 가능.    \n",
    "# 허깅페이스팀 강의\n",
    "https://www.youtube.com/playlist?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
