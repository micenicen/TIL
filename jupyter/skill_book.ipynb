{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩 사용하기 전 실행하는 절차\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fbe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩 사용 2단계\n",
    "strategy = tf.distribute.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 1단계 - 데이터 확인\n",
    "data.info()\n",
    "data.describe()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 2단계 - 데이터 변경\n",
    "data['v1'] = data['v1'].replace(['ham','spam'],[0,1]) \n",
    "data.drop_duplicates(subset=['v2'], inplace=True)         # v2를 기준하여 중복되는 요소 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 3단계 - 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb411f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타. 확인기\n",
    "print('v2열의 유니크한 값 :',data['v2'].nunique())\n",
    "print('메일의 최대 길이 : %d' % max(len(sample) for sample in X_train_encoded))\n",
    "print('메일의 평균 길이 : %f' % (sum(map(len, X_train_encoded))/len(X_train_encoded)))\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test_padded, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정하는 함수\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT STT 시스템\n",
    "import openai\n",
    "# 키 입력 이후 소리를 텍스트로 구현 가능\n",
    "def STT(audio):                                                                # 소리를 텍스트로 구현하는 함수\n",
    "    # 파일 저장\n",
    "    filename='input.mp3'                                                       # 파일이름은 같은위치의 인풋\n",
    "    wav_file = open(filename, \"wb\")                                            # 파일을 열기.\n",
    "    wav_file.write(audio.tobytes())                                            # 파일을 글자로 적기\n",
    "    wav_file.close()                                                           # 작성하고 저장.\n",
    "\n",
    "    # 음원 파일 열기\n",
    "    audio_file = open(filename, \"rb\")                                          # 오디오파일 열기\n",
    "    #Whisper 모델을 활용해 텍스트 얻기                             \n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)              # 오픈AI 위스퍼로 텍스트 얻기\n",
    "    audio_file.close()                                                         # 오디오파일 닫기\n",
    "    # 파일 삭제\n",
    "    os.remove(filename)                                                        # 파일 삭제하기\n",
    "    return transcript[\"text\"]                                                  # 텍스트 리턴하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT에게 질문하기\n",
    "import openai\n",
    "\n",
    "def ask_gpt(prompt, model):                                                    # GPT에게 질문하는 함수\n",
    "    response = openai.ChatCompletion.create(model=model, messages=prompt)      # 오픈AI gpt의 모델과 메세지 전달\n",
    "    system_message = response[\"choices\"][0][\"message\"]                         # 시스템 메세지는 메세지 내용으로 리턴\n",
    "    return system_message[\"content\"]                                           # 응답받기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecec412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트림릿 기준 TTS생성,재생하기\n",
    "def TTS(response):                                                             # TTS를 활용하여 음성 파일 생성하기(자동으로 재생하기)\n",
    "    # gTTS 를 활용하여 음성 파일 생성\n",
    "    filename = \"output.mp3\"                                                    # 음성파일 지정하기.\n",
    "    tts = gTTS(text=response,lang=\"ko\")                                        # gtts로 음성화 시키기\n",
    "    tts.save(filename)                                                         # tts를 저장하기\n",
    "    # 생성은 여기까지 \n",
    "    \n",
    "    # 음원 파일 자동 재성 (사이트에서 재생바 만들어서 보이기)\n",
    "    with open(filename, \"rb\") as f:                                            # 움원파일 열기 \n",
    "        data = f.read()                                                        # 음원파일 읽어들이기\n",
    "        b64 = base64.b64encode(data).decode()                                  # 음원파일 재생 패키지로 디코드 \n",
    "        md = f\"\"\"\n",
    "            <audio autoplay=\"True\">\n",
    "            <source src=\"data:audio/mp3;base64,{b64}\" type=\"audio/mp3\">\n",
    "            </audio>\n",
    "            \"\"\"\n",
    "        st.markdown(md,unsafe_allow_html=True,)                                # 재생바 생성하여 재생시키기\n",
    "    # 파일 삭제\n",
    "    os.remove(filename)                                                        # 사용 이후 파일삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2264606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 학습요령(사이트)\n",
    "# https://y-rok.github.io/pytorch/2020/07/10/pytorch-dynamic-training.html\n",
    "# https://pytorch.org/docs/stable/data.html#map-style-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647c931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b79ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016292e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96650c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파이프라인 연결\n",
    "# from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=\"beomi/llama-2-ko-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f02964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/llama-2-ko-7b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"beomi/llama-2-ko-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a9ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46a3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
