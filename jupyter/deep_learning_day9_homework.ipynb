{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81921940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제1. 이 제품은 너무 좋은데요. 정말 좋아요. 강추합니다. 이런 댓글을 입력했을때 긍정인지 부정인지 출력하는 것을 만들어라.\n",
    "# 이것도 상품인가요? 정말 화가 납니다. 분노가 치밀어요. 개짜증납니다.\n",
    "# 함수를 만들어서 언어를 전달받아서 리턴결과가 긍정인지 부정인지 출력하라. \n",
    "# https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5932d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt   \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cbdc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d2745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['lable']=np.select([total_data.ratings>3],[1],default= 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b958b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop_duplicates(subset=['reviews'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab85dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data1 = total_data[0:20000]\n",
    "total_data2 = total_data[20000:40000]\n",
    "total_data3 = total_data[40000:60000]\n",
    "total_data4 = total_data[60000:80000]\n",
    "total_data5 = total_data[80000:100000]\n",
    "total_data6 = total_data[100000:120000]\n",
    "total_data7 = total_data[120000:140000]\n",
    "total_data8 = total_data[140000:160000]\n",
    "total_data9 = total_data[160000:180000]\n",
    "total_data10 = total_data[18000:199908]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48c93c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1, test_data1 = train_test_split(total_data1, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0432c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, test_data2 = train_test_split(total_data2, test_size = 0.25, random_state = 42)\n",
    "train_data3, test_data3 = train_test_split(total_data3, test_size = 0.25, random_state = 42)\n",
    "train_data4, test_data4 = train_test_split(total_data4, test_size = 0.25, random_state = 42)\n",
    "train_data5, test_data5 = train_test_split(total_data5, test_size = 0.25, random_state = 42)\n",
    "train_data6, test_data6 = train_test_split(total_data6, test_size = 0.25, random_state = 42)\n",
    "train_data7, test_data7 = train_test_split(total_data7, test_size = 0.25, random_state = 42)\n",
    "train_data8, test_data8 = train_test_split(total_data8, test_size = 0.25, random_state = 42)\n",
    "train_data9, test_data9 = train_test_split(total_data9, test_size = 0.25, random_state = 42)\n",
    "train_data10, test_data10 = train_test_split(total_data10, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05979432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['reviews'] = train_data1['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data2['reviews'] = train_data2['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data3['reviews'] = train_data3['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data4['reviews'] = train_data4['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data5['reviews'] = train_data5['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data6['reviews'] = train_data6['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data7['reviews'] = train_data7['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data8['reviews'] = train_data8['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data9['reviews'] = train_data9['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data10['reviews'] = train_data10['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "337b001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data2['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data3['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data4['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data5['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data6['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data7['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data8['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data9['reviews'].replace(\"\",np.nan,inplace=True)\n",
    "train_data10['reviews'].replace(\"\",np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc8a2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1['reviews']=test_data1['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data2['reviews']=test_data2['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data3['reviews']=test_data3['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data4['reviews']=test_data4['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data5['reviews']=test_data5['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data6['reviews']=test_data6['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data7['reviews']=test_data7['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data8['reviews']=test_data8['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data9['reviews']=test_data9['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data10['reviews']=test_data10['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9571dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data2['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data3['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data4['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data5['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data6['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data7['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data8['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data9['reviews'].replace(\"\", np.nan, inplace=True)\n",
    "test_data10['reviews'].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf1705c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5393116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게','.','..']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9c84be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['tokenized']=train_data1['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae24e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2['tokenized']=train_data2['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8083b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3['tokenized']=train_data3['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d444b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data4['tokenized']=train_data4['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d138a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data5['tokenized']=train_data5['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7e4a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data6['tokenized']=train_data6['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0657322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data7['tokenized']=train_data7['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad58c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data8['tokenized']=train_data8['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9acc0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data9['tokenized']=train_data9['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d158c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data10['tokenized']=train_data10['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98d0f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['tokenized']=train_data1['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data2['tokenized']=train_data2['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data3['tokenized']=train_data3['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data4['tokenized']=train_data4['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data5['tokenized']=train_data5['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data6['tokenized']=train_data6['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data7['tokenized']=train_data7['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data8['tokenized']=train_data8['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data9['tokenized']=train_data9['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "train_data10['tokenized']=train_data10['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e0bb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1['tokenized'] = test_data1['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e395d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2['tokenized'] = test_data2['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a79b0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data3['tokenized'] = test_data3['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8d79c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data4['tokenized'] = test_data4['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98a8834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data5['tokenized'] = test_data5['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ed1e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data6['tokenized'] = test_data6['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24ad76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data7['tokenized'] = test_data7['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52361137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data8['tokenized'] = test_data8['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "191c4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data9['tokenized'] = test_data9['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b820c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data10['tokenized'] = test_data10['reviews'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ee435cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1['tokenized'] = test_data1['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data2['tokenized'] = test_data2['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data3['tokenized'] = test_data3['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data4['tokenized'] = test_data4['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data5['tokenized'] = test_data5['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data6['tokenized'] = test_data6['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data7['tokenized'] = test_data7['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data8['tokenized'] = test_data8['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data9['tokenized'] = test_data9['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data10['tokenized'] = test_data10['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "918a6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Data = pd.concat([train_data1,train_data2,train_data3,train_data4,train_data5,train_data6,train_data7,train_data8,train_data9,train_data10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "493088eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Data = pd.concat([test_data1,test_data2,test_data3,test_data4,test_data5,test_data6,test_data7,test_data8,test_data9,test_data10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "31106d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_Data['tokenized'].values\n",
    "y_train = train_Data['lable'].values\n",
    "X_test= test_Data['tokenized'].values\n",
    "y_test = test_Data['lable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7c631785",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7a9f7415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 108288\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 63656\n",
      "단어 집합에서 희귀 단어의 비율: 58.78398345153665\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.7521878117316376\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index)\n",
    "rare_cnt = 0\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58bab3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 44634\n"
     ]
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 2          # 2를 더한 이유는 0이라는 패딩토큰에 OOV 토큰 하나가 더 추가되었기 때문이다\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "252ad9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')              \n",
    "early_stop = EarlyStopping(monitor='loss', patience=5)      \n",
    "checkpoint = ModelCheckpoint('lstm2_checkpoint.h5',\n",
    "                             monitor='loss', verbose=1,\n",
    "                             save_best_only=True, mode='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac93a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')                        \n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2ce27ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a3f34c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 77\n",
      "리뷰의 평균 길이 : 13.07044147499733\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5dda9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen = 77)  # 최대길이  77\n",
    "X_test = pad_sequences(X_test, maxlen = 77)     # 임베딩을 위해서 패딩을 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04c9b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ca34850",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "47e2d865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.8991\n",
      "Epoch 1: val_acc improved from -inf to 0.91714, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 273s 75ms/step - loss: 0.2663 - acc: 0.8991 - val_loss: 0.2284 - val_acc: 0.9171\n",
      "Epoch 2/30\n",
      "   1/3620 [..............................] - ETA: 5:04 - loss: 0.1017 - acc: 0.9833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9268\n",
      "Epoch 2: val_acc improved from 0.91714 to 0.92728, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 279s 77ms/step - loss: 0.2084 - acc: 0.9268 - val_loss: 0.2050 - val_acc: 0.9273\n",
      "Epoch 3/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9382\n",
      "Epoch 3: val_acc improved from 0.92728 to 0.93210, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 281s 78ms/step - loss: 0.1810 - acc: 0.9382 - val_loss: 0.1948 - val_acc: 0.9321\n",
      "Epoch 4/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9470\n",
      "Epoch 4: val_acc improved from 0.93210 to 0.93897, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 278s 77ms/step - loss: 0.1599 - acc: 0.9470 - val_loss: 0.1789 - val_acc: 0.9390\n",
      "Epoch 5/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9539\n",
      "Epoch 5: val_acc improved from 0.93897 to 0.94122, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 282s 78ms/step - loss: 0.1424 - acc: 0.9539 - val_loss: 0.1761 - val_acc: 0.9412\n",
      "Epoch 6/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9592\n",
      "Epoch 6: val_acc did not improve from 0.94122\n",
      "3620/3620 [==============================] - 285s 79ms/step - loss: 0.1280 - acc: 0.9592 - val_loss: 0.1859 - val_acc: 0.9361\n",
      "Epoch 7/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9631\n",
      "Epoch 7: val_acc improved from 0.94122 to 0.94483, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 285s 79ms/step - loss: 0.1157 - acc: 0.9631 - val_loss: 0.1696 - val_acc: 0.9448\n",
      "Epoch 8/30\n",
      "3619/3620 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9669\n",
      "Epoch 8: val_acc improved from 0.94483 to 0.94864, saving model to best_model.h5\n",
      "3620/3620 [==============================] - 284s 78ms/step - loss: 0.1048 - acc: 0.9669 - val_loss: 0.1599 - val_acc: 0.9486\n",
      "Epoch 9/30\n",
      "1629/3620 [============>.................] - ETA: 2:21 - loss: 0.0925 - acc: 0.9706"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[es, mc], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4a663161",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52f62be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2828/2828 [==============================] - 55s 19ms/step - loss: 0.1792 - acc: 0.9413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17918553948402405, 0.9413110613822937]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa521ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad(string):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "84e2eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 제품은 너무 좋은데요 정말 좋아요 강추합니다'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "repla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e3b7a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이', '제품', '은', '너무', '좋은데', '요', '정말', '좋아요', '강', '추합니다']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "repla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18e1a29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d9eec30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_and_bad(input_text):\n",
    "    repla = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", input_text)\n",
    "    repla2 =okt.morphs(repla)\n",
    "    stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게','.','..']\n",
    "    repla3 = []\n",
    "    for item in repla2: \n",
    "        if item not in stopwords:\n",
    "            repla3.append(item)\n",
    "    repla4 = [item for sublist in tokenizer.texts_to_sequences(repla3) for item in sublist]\n",
    "    repla5  = pad_sequences([repla4] , maxlen = 77) \n",
    "    ans = loaded_model.predict(repla5)\n",
    "    if ans[0][0]>0.5:\n",
    "        print('긍정입니다.')\n",
    "        print(f'출력결과{ans[0][0]*100}')\n",
    "    else:\n",
    "        print('부정입니다.')\n",
    "        print(f'출력결과{ans[0][0]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e00def38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "긍정입니다.\n",
      "출력결과98.92106652259827\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "부정입니다.\n",
      "출력결과0.9549354203045368\n"
     ]
    }
   ],
   "source": [
    "good_and_bad('이 제품은 너무 좋은데요. 정말 좋아요. 강추합니다.')\n",
    "good_and_bad('이것도 상품인가요? 정말 화가 납니다. 분노가 치밀어요. 개짜증납니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d9e3f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "부정입니다.\n",
      "출력결과1.425912231206894\n"
     ]
    }
   ],
   "source": [
    "good_and_bad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbd5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
