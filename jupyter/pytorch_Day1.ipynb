{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec4a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 문법\n",
    "# 그동안에 했던 것은 텐서플로 기반으로 사용했다. \n",
    "# 케라스는 텐서플로 기반이다. 버젼은 두 가지가 존재한다. 우리가 한 것은 초보자 버젼이다. 간략한 설정을 부여 가능하다.\n",
    "# 진짜 텐서플로는 자세하다. 공부할 것이 훨씬 많다. \n",
    "# 과거에는 텐서플로가 유행했었다. 지금은 텐서플로, 파이토치가 반반이다. 파이토치를 사용할 수 있는 사람도 요구한다.\n",
    "# 파이토치는 쉬운 편이다. 케라스와 비슷한 수준이다. \n",
    "# 코딩 시간이 짧고 기능도 많다. \n",
    "# 취업처를 찾을 때 데이터라고 검색하자. \n",
    "# sql도 특강이 예정되어있다. 2일 정도 들을 예정이다. \n",
    "# LLM은 경력자를 많이 뽑는다.\n",
    "# 텐서플로, 파이토치도 많이 뽑는 편이다.\n",
    "# 파이토치는 활용하기 좋을 것이다. 바로 실습하면서 알아보자. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16135ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝프레임워크는 여러가지가 있다. 텐서플로, 파이토치등등 존재한다.\n",
    "# 과거는 텐서플로가 유행했으나 지금은 파이토치가 유행하는 시기이다. 파이토치는 튜토리얼이 존재한다. \n",
    "# https://tutorials.pytorch.kr/?_gl=1*1f3w7gi*_ga*NTQxMTA4OTQuMTY1NzM0MzMzMA..*_ga_LEHG248408*MTY1ODA2Mzg0NS4zLjEuMTY1ODA2Mzg0OC41Nw\n",
    "# 한국어 파이토치 튜토리얼이다. 시간나면 여기서 배우자. \n",
    "# 파이토치는 용어를 배우는 것이 중요하다. 용어에서 막히는 경우가 종종 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7116dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 용어\n",
    "# 파이토치라는 패키지는 딥러닝 프레임워크이다. 토치는 기본이 되는 네임스페이스다. \n",
    "# 넘파이하고 상당히 유사하다. 수학관련 함수가 많이 쓰인다. \n",
    "# 토치.오토그래드라고 해서 자동미분함수도 존재한다. 경사하강법도 전부 가능하다.\n",
    "# 유튜브 영상도 존재하니 배우는 것은 제대로 배워보자. \n",
    "# 이런 것을 참고하여 공부하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71666eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치는 2가지 주요 특징이 있다. \n",
    "# 1. 넘파이와 유사하다. 선형대수에서 다루는 다양한 연산을 빠르게 수행 가능하다. \n",
    "#   GPU상에서 실행 가능한 n차원 텐서(다차원 배열)로 구성된다. \n",
    "#   데이터를 저장하고 다루는 단위는 벡터(1차원 형태로 구성),행렬(2차원 형태로 구성), 텐서(3차원 형태로 구성), 스칼라(0차원)가 존재한다. \n",
    "#   텐서는 3차원 이상부터 해당한다. 3차원이 여러개가 뭉쳐서 4차원, 5차원 이렇게 갈 것이다. \n",
    "#   또는 3차원 이상의 배열을 다차원 배열로 부른다. \n",
    "# 2. 신경망을 구성하고 학습하는 과정에서 자동으로 미분을 하게된다. \n",
    "#   외부적으로 구현되어져 있다. \n",
    "#   2차원 텐서를 나타낼때는 (배치사이즈(2차원 텐서), 차원) 로 표시한다. \n",
    "#   하나의 훈련데이터 크기가 256차원이라고 가정하자. 256개의 수치데이터들이 존재할 것이다. 이와 같은 데이터가 3000개가 있다면?\n",
    "#   (3000,256)이 2차원 텐서일 것이다. \n",
    "#   컴퓨터가 한번에 처리하는 2차원 텐서의 크기를 말할 때 (3000,256) 이렇게 표시해야 한다. \n",
    "#   비전분야에서는 3차원 텐서가 주로 사용된다. 얘들은 (배치사이즈, 폭, 높이)로 표현된다. \n",
    "#   자연어 처리분야보다는 비전처리, 영상처리등이 여러 장의 사진을 쓰는 분야다보니 단위가 크다. \n",
    "#   이와 같은 데이터를 표현할 때 이미지가 있었는데 이런 이미지를 위로 쌓아올렸다고 이해하면 된다. \n",
    "#   (3000,1920,1028) 이런식으로 표시된다. \n",
    "#   자연어는 꽤 다르다. (배치사이즈, 길이(타임스텝), 벡터크기(디멘젼))으로 나타내는 3차원 텐서이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5513bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장이 이중리스트로 있다고 해보자. [[문장],[문장],....[n개의 문장]]\n",
    "# 문장단위로 나누고 단어단위로 나눈 다음 2차원 텐서구조로 벡터로 표현하게 된다. \n",
    "# 3차원 공간에 임베딩을 한다면.\n",
    "# 3차원 공간에 표현이 되어진다면 단어1 = [0.3,0.7,1.5] 와 같이 나타낼 것이다. \n",
    "# 이것이 어떻게 바뀌게 되느냐. 대괄호가 두 개가 있으며 각각의 단어들이 임베딩이 된다고 하자. 삼중리스트로 저런 숫자들이 나열된다.\n",
    "# 대단원[문장[단어]]이런 식으로 나눠지게 되는 것이다. \n",
    "# [나는 사과를 좋아해, 나는 망고를 싫어해] 라고 된다면 [[[나는],[사과를],[좋아해]],[[나는],[망고를],[싫어해]]]\n",
    "# 이런 식으로 3차원화하여 숫자화(토큰화)되어서 나타날 것이다. [[[1,2,3],[4,5,6],[7,8,9]],[[1,2,3],[10,11,12],[13,14,15]]]\n",
    "# 훈련데이터를 이런 식으로 구성한다.\n",
    "#\n",
    "# 배치사이즈를 1로 했다고 가정하자. \n",
    "# 첫번째 배치를 훈련해보면 다음과 같이 훈련된다.  텐서크기는 [1,3,3]이 여러번 오는 모양이다. \n",
    "# 첫번째 텐서\n",
    "# [[[[1,2,3],[4,5,6],[7,8,9]]]] \n",
    "# 두 번째 텐서\n",
    "# [[[1,2,3],[10,11,12],[13,14,15]]]\n",
    "# \n",
    "# 문장을 하나씩 읽어서 학습을 하게 된다. \n",
    "# 이후 백프라퍼게이션을 통해서 업데이트를 하게 된다.\n",
    "#\n",
    "# 배치사이즈를 2로 하면 \n",
    "# 첫번째 텐서\n",
    "# [[[[1,2,3],[4,5,6],[7,8,9]]]] \n",
    "# [[[1,2,3],[10,11,12],[13,14,15]]]\n",
    "# 두번째 텐서\n",
    "# [[[[1,2,3],[4,5,6],[7,8,9]]]] \n",
    "# [[[1,2,3],[10,11,12],[13,14,15]]]\n",
    "# 이런 식으로 학습될 것이다. \n",
    "# \n",
    "# 문장을 전부 한바퀴 돌면 1에폭을 돌린 것이다. \n",
    "# 학습을 할 때 이런 구조적은 측면에서 용어의 정리가 필요하다. \n",
    "# 넘파이를 이용해서 텐서를 만들고 파이토치를 이용해서 텐서를 만들어보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951eeef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 넘파이로 텐서를 만드는 방법.\n",
    "# 1차원 텐서를 만들어보자. \n",
    "t = np.array([1,2,3,4])\n",
    "t\n",
    "# 이게 1차원 텐서다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d338931c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.ndim # 텐서의 차원이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23222e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape # (4,)의 의미는 1행 4열 (1,4)를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e0b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 텐서는 2차원 리스트구조로 만들 수 있다. \n",
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5831dd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.],\n",
       "       [ 7.,  8.,  9.],\n",
       "       [10., 11., 12.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t # 2차원 배열이자 2차원 텐서이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3733f6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.ndim # 똑같이 2차원 텐서이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de5f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape # 크기는 (4,3)이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80b9b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.0-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "   ---------------------------------------- 0.0/192.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/192.3 MB 7.9 MB/s eta 0:00:25\n",
      "   ---------------------------------------- 1.0/192.3 MB 13.3 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 2.1/192.3 MB 16.6 MB/s eta 0:00:12\n",
      "    --------------------------------------- 3.3/192.3 MB 19.5 MB/s eta 0:00:10\n",
      "    --------------------------------------- 4.2/192.3 MB 22.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 4.2/192.3 MB 22.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 4.2/192.3 MB 22.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 4.6/192.3 MB 12.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 5.9/192.3 MB 14.4 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 7.0/192.3 MB 15.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 8.2/192.3 MB 16.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 9.3/192.3 MB 17.1 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 10.5/192.3 MB 18.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 11.8/192.3 MB 19.3 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 13.0/192.3 MB 18.7 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 14.3/192.3 MB 18.7 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 15.6/192.3 MB 26.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 17.0/192.3 MB 26.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 18.4/192.3 MB 26.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 19.7/192.3 MB 28.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 21.1/192.3 MB 28.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 22.4/192.3 MB 28.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 23.9/192.3 MB 28.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 25.3/192.3 MB 28.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 26.5/192.3 MB 28.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 27.8/192.3 MB 28.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 29.0/192.3 MB 28.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 30.4/192.3 MB 28.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 31.9/192.3 MB 28.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 33.5/192.3 MB 29.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 35.4/192.3 MB 31.2 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 37.0/192.3 MB 31.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.3/192.3 MB 32.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 39.5/192.3 MB 32.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 40.8/192.3 MB 31.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 42.1/192.3 MB 31.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 43.4/192.3 MB 29.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 45.0/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 46.7/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 48.0/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 49.5/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 51.1/192.3 MB 31.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 52.4/192.3 MB 31.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 53.5/192.3 MB 29.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 55.1/192.3 MB 29.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 56.6/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 58.0/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 59.4/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 61.2/192.3 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 62.9/192.3 MB 32.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 64.9/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 66.3/192.3 MB 34.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 68.0/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 69.7/192.3 MB 36.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 71.3/192.3 MB 38.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 72.8/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 74.3/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 75.8/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 77.7/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 79.2/192.3 MB 32.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 81.0/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 82.6/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 83.8/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 85.3/192.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 86.9/192.3 MB 32.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 88.4/192.3 MB 32.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 89.6/192.3 MB 31.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 90.8/192.3 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 92.1/192.3 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 93.3/192.3 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 94.4/192.3 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 95.4/192.3 MB 26.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 96.5/192.3 MB 26.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 97.6/192.3 MB 25.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 98.8/192.3 MB 24.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 99.9/192.3 MB 24.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 101.2/192.3 MB 25.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 102.5/192.3 MB 25.1 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 103.6/192.3 MB 25.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 104.8/192.3 MB 25.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 106.1/192.3 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 107.3/192.3 MB 25.1 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 108.6/192.3 MB 27.3 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 109.8/192.3 MB 27.3 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 111.2/192.3 MB 26.2 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 113.0/192.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 114.7/192.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 116.6/192.3 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 118.7/192.3 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 120.3/192.3 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 121.8/192.3 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 123.8/192.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 125.8/192.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 127.2/192.3 MB 38.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 128.4/192.3 MB 36.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 129.5/192.3 MB 34.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 130.3/192.3 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 131.0/192.3 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 131.7/192.3 MB 27.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 132.6/192.3 MB 26.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 133.5/192.3 MB 24.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 134.3/192.3 MB 22.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 135.3/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 136.4/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 137.7/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 139.0/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 140.0/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 141.0/192.3 MB 21.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 142.0/192.3 MB 22.6 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 143.1/192.3 MB 22.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 144.1/192.3 MB 23.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 145.0/192.3 MB 23.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 146.1/192.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 147.4/192.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 149.1/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 150.6/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 151.9/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 153.1/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 154.3/192.3 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 155.2/192.3 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 155.2/192.3 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 156.4/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 157.7/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 159.1/192.3 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 160.7/192.3 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 162.5/192.3 MB 25.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 163.9/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 165.1/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 166.2/192.3 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 166.9/192.3 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 167.8/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 168.6/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 169.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 170.0/192.3 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 170.8/192.3 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 171.6/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 172.4/192.3 MB 19.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 173.3/192.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 174.2/192.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 175.5/192.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 176.8/192.3 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.3/192.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 179.7/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 181.1/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 182.6/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 184.4/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 186.2/192.3 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 186.6/192.3 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 187.1/192.3 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  189.1/192.3 MB 28.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  191.0/192.3 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 192.3/192.3 MB 13.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n",
    "# 먼저 파이토치를 설치하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3595e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56bcd188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])  # 플롯텐서, 인트텐서 등 텐서를 어떤 방식으로 만들지 나올 것이다. \n",
    "t                                                    # 어레이가 아니라. 텐서라고 표시된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f5507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dim()            # 차원을 나타낸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e51985a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape           # 괄호없이 모양보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b19f8a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()          # 괄호가지고 모양보기\n",
    "                  # 괄호가 있는 이유는 t가 이 함수(매서드)를 가지고 있다는 뜻이다. 괄호없으면 속성(어트리부트)라고 부른다. \n",
    "                  # 함수는 기능을 가지고 있다.\n",
    "                  # 자동차(클래스)에서 파생된 내차(객체)가 달린다(함수)로 표현 가능하다.\n",
    "                  # 여기서 t는 내차의 포지션이다. 일반적으로 Float같이 대문자로 시작하면 클래스 함수라고 정의한다. \n",
    "                  # (FloatTensor)클래스는 달리는 기능을 가진다. 여기서 내 차(t)라는 실체가 달리는(.size())것이다. \n",
    "                  # 클래스 괄호안에 객체의 재료를 담으면 객체가 생성된다. 그리고 그 객체를 함수로 동작시킨다. \n",
    "                  # 동작은 함수다. 달리기, 멈추기, 쌍라이트 등이다. \n",
    "                  # 속성은 info와 같다. 구동, 배기량 등을 말한다. \n",
    "                  # 속성과 함수는 구분되어야 한다. \n",
    "                  # 객체지향에 대해 제대로 이해하려면 1년이 넘게 걸린다. \n",
    "                  # 결론\n",
    "                  # 클래스는 설계도면이다. \n",
    "                  # 객체는 설계도로 만들어진 하나의 실체이다. \n",
    "                  # 함수는 객체의 작동 매커니즘이다. \n",
    "                  # 속성은 객체의 특성, 스텟이다.\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ebd00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체지향적이라는 말은 객체를 중심으로 프로그래밍한다는 것이다. 기존꺼 못쓰면 기존거를 재사용한다. \n",
    "# 기존에 가지고 있던 특성, 동작을 일부 수정,변경해서 새로 사용한다는 것이다. \n",
    "# 비용절약, 개발시간 단축, 안정성등의 장점이다. \n",
    "# 파이썬, 자바, C++ 모두가 객체지향적 언어이다. \n",
    "# \n",
    "# 코드로 무엇인가를 만들어서 진행하는 것은 절차지향적이라고 한다. 기존꺼 못쓰면 다른것을 계속 만들어야 한다. \n",
    "# 아예 새로 만드는 매커니즘이다. 과거에는 절차지향적 코딩을 많이했었다. \n",
    "# 어셈블리어등이 여기에 해당한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "703504f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3]            # 넘파이와 매커니즘은 동일히다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e017f2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 4.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[2:5]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af554193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:5]          # 넘파이에 익숙하다면 어렵지 않다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "296d00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7baec642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dim()        # 차원은 2차원이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e84ad2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape        # 모양은 4,3이다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "479786af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5.,  8., 11.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1]         # 행은 전부 가져오고 두번째 차원을 가져오라는 이야기이다. 동일하다. 마이너스 인덱스도 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d3601cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1].size()  # 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa18d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬의 덧셈뺄셈은 두 행렬의 크기가 같아야 가능했지만 넘파이는 브로드캐스팅이 가능했다.\n",
    "# 행렬연산은 조건이 존재한다. 덧셈, 뻴셈을 하는 경우는 반드시 두 행렬의 크기가 같아야 한다.\n",
    "# 행렬연산의 곱셈은 마지막차원과 첫번째차원이 일치해야 한다. \n",
    "# 자동으로 크기를 조절하게 해서 연산을 가능하게 만드는 것이 브로드캐스팅이다. 크기를 맞춰서 두 행렬이 연산 가능하게 하는 것이다. \n",
    "t1 = torch.FloatTensor([[1,1]])\n",
    "t2 = torch.FloatTensor([[2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b0acdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+t2 # 크기가 동일하면 무난하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49e2ed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.FloatTensor([[1,1]])\n",
    "t4 = torch.FloatTensor([3])\n",
    "t3+t4                           # 브로드캐스팅으로 1차원과 2차원이 더해졌다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55879d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5 = torch.FloatTensor([[1,3]])   # 1,2의 행렬이다. \n",
    "t6 = torch.FloatTensor([[3],[4]]) # 2,1의 행렬이다. \n",
    "t5+t6                             # 더해졌다.한쪽이 증식해서 맞춰진 것이다. \n",
    "                                  # [1,3]      [3,3]\n",
    "                                  #         + \n",
    "                                  # [1,3]      [4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169853e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t6+t5                             # 브로드캐스팅은 크기가 다르더라도 확장이 된다. 원하든 원하지 않든 이루어진다. \n",
    "                                  # 문제는 이 점을 간과하면 찾기가 어렵다는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "707cb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.FloatTensor([[1, 2], [3, 4]]) # 2,2의 크기를 가진다. \n",
    "m2 = torch.FloatTensor([[1], [2]])       # 2,1의 크기를 가진다. \n",
    "                                         # 이 두 개를 곱해보자. 매트릭스 멀티플라이라고 부른다. \n",
    "                                         # 파이토치에서는 matmul이라고 쓴다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e1f6778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.matmul(m2)                            # 위에 (1)*1 + (2)*2 = 5이다.\n",
    "                                         # 아래는 (3)*1 + (4)*2 = 11 이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d3a20ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m2\u001b[38;5;241m.\u001b[39mmatmul(m1)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)"
     ]
    }
   ],
   "source": [
    "m2.matmul(m1)                            # 열이 2개가 있어야 행 2개랑 곱할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70aa774a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1*m2 # 결과가 다르긴 하다. 증식해서 곱해진 것이다. 행은 행끼리, 열은 열끼리 곱해졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76076bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균을 구하는 것은 넘파이의 mean하고 비슷하다. \n",
    "t = torch.FloatTensor([1,2])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20825470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean() # 평균은 1.5로 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be2bc47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1d8aa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean() # 전체평균이 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6883430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(dim=0) # 행 단위로 1번째 차원으로 계산하라는 것이다.열끼리 평균이 나왔다. axis = 1과 같은 효과이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39ec3b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(dim=1) # 열 단위로 1번째 차원을 계산하라는 것이다.행끼리 평균이 나왔다.  axis = 0과 같은 효과이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0522e720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "t.sum()                                 # 내부숫자를 전부 더해버렸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f18e5ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=1)                           # 행끼리 더해져서 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46d3704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=0)                           # 열 끼리 더해졌다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c4aa4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()                                # 모든 값 중 최댓값이 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0236aadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([3., 4.]),\n",
       "indices=tensor([1, 1]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(dim=0)                          # 최대값이 나오고 argmax도 같이 나온다.              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8922465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(dim=0)[1]                       # 물론 따로 추출도 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f501ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뷰\n",
    "# 파이토치에는 뷰라고 하는 것이 존재한다. \n",
    "# 넘파이 시절 모양을 변경시킬때 reshape를 썼던 기억이 있을 것이다. \n",
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0a2e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.shape # 3차원의 구조이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7713b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,3]) # 가끔 쓰이는 reshape 함수이다. \n",
    "# 뷰 함수는 텐서의 크기를 변경하는 함수이다. \n",
    "# 크기를 변경하는 방법은 -1,3으로 변경한다는 것이다. 즉 (?,3)으로 표현하는 것이다. 모르겠으니 알아서 하라는 것이다. \n",
    "# [2,2,3] 이라는 3차원 텐서를 2차원 텐서인 (?,3)으로 바꾸라는 것이다. \n",
    "# 12개의 요소들을 열을 3으로 확정하고 행의 개수는 알아서 계산한다.\n",
    "# 12개의 요소로 구성되어져 있는 3차원 텐서를 열의 갯수가 3으로 고정된 2차원 텐서로 바꾸기에 (4,3) 텐서가 만들어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8930a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "876edea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 5]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ft\u001b[38;5;241m.\u001b[39mview([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 5]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "ft.view([-1,5]).shape\n",
    "# 약수관계에 없으면 애러가 뜨게 될 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "247e114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([4,-1]) # 아까랑 비슷하게 뜨게 된다. \n",
    "# 그리고 ft(2,2,3)을 다시 바꿔서 (?,1,3)으로 바꿔보고 싶다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c83192d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.]],\n",
       "\n",
       "        [[ 3.,  4.,  5.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.]],\n",
       "\n",
       "        [[ 9., 10., 11.]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,1,3]) # 다양한 구조로 텐서를 변경할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c3ad04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스퀴즈 함수\n",
    "ft=torch.FloatTensor([[0],[1],[2]])\n",
    "ft                                    # (3,1) 행렬을 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae173d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2차원 구조의 텐서를 1차원 구조의 텐서로 만들고자 한다면?\n",
    "ft.squeeze()# 1차원으로 늘어졌다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe7348c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2=torch.FloatTensor([[0,1],[2,3],[4,5]])\n",
    "ft2           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f154b1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2.squeeze() # 삭제 되지 않았다. \n",
    "              # 스퀴즈는 크기가 1인 차원을 제거해주는 함수이다. 즉 1에 해당하는 차원을 제거하는 목적으로 사용한다. \n",
    "              # 3행 2열이기에 제거되는 차원이 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6b88fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 언스퀴즈(unsqueeze)\n",
    "# 크기가 1인 차원을 특정위치에 추가하는 것이다. 스퀴즈와 반대이다. \n",
    "ft = torch.Tensor([0, 1, 2])\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08f6a0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크기가 1인 차원을 추가해보자. \n",
    "ft.unsqueeze(0)                # 첫번째 차원에 추가한 것이다. 변화가 없다. 행 부분이 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2cec92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.unsqueeze(1)                # 두번째 차원에 추가한 것이다. (3,1)으로 바뀌었다. 열 부분이 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2113e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 자료형\n",
    "# 파이토치는 실수형도 있지만 정수형도 존재한다. \n",
    "# float텐서는 32비트로 정의된다. 정수는 int텐서는 32비트와 64비트가 된다. \n",
    "# https://pytorch.org/docs/stable/tensors.html 이 사이트에서 확인이 가능하다.\n",
    "# 64비트는 10에 300승 정도를 표현할 수 있다. \n",
    "# 16비트는 10에 30승 가량을 표현할 수 있다. \n",
    "# 정수는 정수를 표현하는 가장 큰 타입이 long타입이다. 8바이트를 잡아먹는다. 921경으 표현 가능하다. \n",
    "# 인티저는 4바이트를 잡아먹는다. \n",
    "# 그래서 엄청 큰 수는 float을 쓴다. 더 크면 double을 쓴다. \n",
    "# 이번에 long텐서를 만들어보자. \n",
    "lt = torch.LongTensor([1, 2, 3, 4])\n",
    "print(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "259eac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 만약 실수가 있고 정수가 있다면 정수로 통합된다. \n",
    "lt = torch.LongTensor([1., 2., 3, 4])\n",
    "print(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92eb7ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt.float() # 일괄적으로 실수로 변환되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65deb564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "bt = torch.ByteTensor([True, False, True, False])\n",
    "print(bt)                                 # 불린은 바이트로 표시해도 지장없다. \n",
    "                                                 # unsigned int 8비트 라는 뜻이다. \n",
    "                                                 # 사실 불린은 1 또는 0으로 표현할 수 있다. 바이트텐서 이상의 공간을 쓸 필요는 없다. \n",
    "                                                 # uint는 0부터 255까지 표현 가능하다. \n",
    "                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb8e2575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.long() # 롱으로 바뀌었다.이제 아주 큰 수도 저장이 가능해진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8080573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([255,   0,   1,   0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "bt = torch.ByteTensor([255, False, True, False]) # 255까지 가능하다. 넘어가면 오버플로우 애러가 뜬다. \n",
    "print(bt)                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "430c37ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1234567891234567891,                   0,                   1,\n",
      "                          0])\n"
     ]
    }
   ],
   "source": [
    "bt = torch.LongTensor([1234567891234567891, False, True, False]) # 921경까지 가능하다. \n",
    "print(bt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "da3c10ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2346e+22, 0.0000e+00, 1.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "bt = torch.FloatTensor([12345678912345678912345, False, True, False]) # 플롯은 그 이상의 숫자도 가능하다.\n",
    "print(bt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1894e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat 함수\n",
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])\n",
    "# 예전에는 .merge .join .concat등 많은 함수를 사용했다. \n",
    "# 여기서는 cat 함수를 쓴다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ffb02ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b59e673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14736bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y]) # 합쳐졌다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66fc4c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y],dim=0) # 디폴트이다. 첫 번째 차원이 늘어난다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e4f82bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 5., 6.],\n",
       "        [3., 4., 7., 8.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y],dim=1) # 두 번째 차원으로 늘어났다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66938424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서들끼리 연산하는 경우가 종종 보인다. \n",
    "# 텐서들끼리 합쳐지는 경우가 있다. 중간중간 연산속에서 서로 다른 텐서를 연결하는 경우가 있을 것이다. \n",
    "# 이런 상황에서 cat은 유용하게 사용되어질 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07218c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹\n",
    "x = torch.FloatTensor([1, 4])\n",
    "y = torch.FloatTensor([2, 5])\n",
    "z = torch.FloatTensor([3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "656b6169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7fc79632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1be2b727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5bd48c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3개의 텐서가 존재하는 상태이다. 3개의 벡터를 모두 연결하려고 한다. \n",
    "torch.stack([x,y,z]) # 참고로 적은 순서대로 합쳐진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6930ebe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [3., 6.],\n",
       "        [2., 5.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x,z,y]) # 순서를 바꾸면 이러한 모양이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28aa5fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 원스 라이크, 제로스 라이크\n",
    "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n",
    "print(x)                                        # 2,3의 크기를 가진 텐서이다. \n",
    "                                                # 텐서의 크기를 그대로 두되 새롭게 0 또는 1로 값을 채우는 것을 원할 때 쓴다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7817e80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(x)                              # 구조는 같고 내용은 전부 1로 바뀐다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b90fb493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(x)                             # 구조는 같고 내용은 전부 0으로 바뀐다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c69bb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])        # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b21868fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x                                              # 2차원 구조의 텐서가 만들어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35c4256a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*2                                            # 2를 곱했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "110476dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mul(2)                                       # 2를 곱하는 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8353f160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mul_(2)                                      # 만약에 함수 뒤에 언더바를 붙이면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c67878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x                                             # 덮어쓰기도 함께 수행된다는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c021489",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 0                                    # 먼저 결과값을 저장해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "501d51f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(num):                                 # 외부로부터 값을 전달받는 함수가 있다고 해보자. \n",
    "    result +=num\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c75c8c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'result' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m add(\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[119], line 2\u001b[0m, in \u001b[0;36madd\u001b[1;34m(num)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(num):                                 \u001b[38;5;66;03m# 외부로부터 값을 전달받는 함수가 있다고 해보자. \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mnum\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'result' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "add(3)                                        # result는 지역변수로 취급되어 접근할 수 없다고 나온 것이다. \n",
    "                                              # result는 바깥쪽에 선언되어져 있다. 전역변수이다. \n",
    "                                              # 만약 쓰고싶다면 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "344ad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(num):                                 # 외부로부터 값을 전달받는 함수가 있다고 해보자. \n",
    "    result = 1\n",
    "    result +=num\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a1bebdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(3)                                        # 함수 자체는 작동한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b93a9641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(result)                                 # 지역변수와 전역변수는 구분된다. 함수는 블록 내에서만 사용된다. \n",
    "                                              # 함수 바깥에 있는 result는 전역변수이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aba913e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(num):                                \n",
    "    global result\n",
    "    result +=num\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d71b11b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(3)                                       # 글로벌을 써서 전역변수를 쓰면 된다. \n",
    "                                             # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "151607eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = 0\n",
    "result2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b8aab0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add1(num):\n",
    "    global result1\n",
    "    result1 +=num\n",
    "    return result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7b79452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(add1(3))                               # 먼저 여기까지는 알 것이다. \n",
    "print(add1(4))                               # 함수는 계속 이어져서 사용될 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32b6645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2(num):\n",
    "    global result2\n",
    "    result2 += num\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0de8bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(add2(2))                  \n",
    "print(add2(6))                               # 여기서 두 개의 계산기는 별개이다. \n",
    "                                             # 문제는 계산기가 비슷하다. 이거로 일일히 계산기를 만드는 것은 매우 비효율적이다. \n",
    "                                             # 그래서 클래스라는 개념을 사용한다. \n",
    "                                             # 클래스를 통해서 계산기를 여러개 만드는 상황을 정의하자는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f9349835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator:\n",
    "    def __init__(self):        # 클래스로부터 객체가 생성될때 자동으로 호출되는 함수이다. 생성자함수라고 부른다. \n",
    "        self.result = 0        # 객체에 대한 초기작업을 수행하는 부분이다. \n",
    "        print('생성자 호출됨') # 수행 정상적으로 이루어졌다. \n",
    "\n",
    "    def add(self, num):        # 함수를 호출한다. \n",
    "        print('add함수 호출됨')# 결과수행을 보자. \n",
    "        self.result += num     # 작동은 다음과 같이 이루어진다. \n",
    "        return self.result     # 결과를 리턴한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fe5ca30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성자 호출됨\n",
      "생성자 호출됨\n"
     ]
    }
   ],
   "source": [
    "# 객체 생성 \n",
    "cal1 = Calculator()            # 실체가 만들어졌다. \n",
    "cal2 = Calculator()            # 객체를 두 번 호출했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7c7462fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add함수 호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal1.add(3)                    # 이렇게 함수가 제작되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "32b5dd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add함수 호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal2.add(6)                    # 마음만 먹으면 객체를 얼마든지 만들 수 있게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "96e44f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀모델을 torch에서 구현하기.\n",
    "# 선형회귀모델을 torch에서 만들때는 뉴럴 네트워크를 호출해야한다. \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "33cc222d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x268b42ffb30>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "782f92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "3e38df4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 이상적인 회귀모델은 y = 2x가 가장 이상적인 모델일 것이다. \n",
    "# 이때 최적의 웨이트와 bias는 편미분도 하고 업데이트하고 코스트를 구해서 훈련할 것이다. \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2d050337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀모델을 만들때 w와 b를 선언해야 한다. 텐서플로시절에는 일일히 지정해주지 않았다. \n",
    "# 여기서는 모델을 만들때 가중치를 먼저 정의한다. \n",
    "W=torch.zeros(1,requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "9faa53f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W # 초기값은 0으로 줬다. 최종적으로 W는 2에 가까워질것이다. \n",
    "# requires_grad는 업데이트가 이루어지는 변수라는 뜻이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "c2a75dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=torch.zeros(1,requires_grad = True) # bias도 똑같이 변수에 해당한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "71c326c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3593],\n",
       "        [4.0671],\n",
       "        [5.7749]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기모델은 y = 0*x+0에서 출발하는 것이다. \n",
    "# 현재는 x를 기어가는 모델이다. \n",
    "# w,b를 둘 다 업데이트 해야한다. 그래서 가설함수를 제작해야한다. \n",
    "# hx(가설함수) =W * x_train + B\n",
    "hx = W * x_train + B\n",
    "hx                            \n",
    "# 초기값들인 0이다. \n",
    "# 아래로 볼록한 코스트 함수가 그려져 있어야 한다. \n",
    "# 그렇게 W와 B를 업데이트 해야한다. 편미분을 통해 업데이트 해야한다. \n",
    "# 텐서플로의 원 버젼도 이런 식으로 업데이트를 해야한다. 디테일하게 코딩해야한다. \n",
    "\n",
    "# 잠시후 여기를 반복해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "fbc1de67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0614, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코스트 함수 정의하기\n",
    "cost = torch.mean((hx - y_train)**2)  # 정답과 제출답의 제곱평균을 구한다. 이것이 코스트이다. \n",
    "cost                                  # 미분을 통해 w를 업데이트 한다. 경사하강법도 직접 구현해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e75520e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W,B], lr=0.01) # 옵티마이저를 다음과 같이 설정했다. \n",
    "# 학습을 할 대상은 W와 B이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "288635c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()          # 미분을 해서 구한 기울기를 0으로 초기화해주는 부분이다. \n",
    "cost.backward()                # 백프라퍼게이션이 생각난다. W와 B에 대한 기울기가 계산이 된다. \n",
    "optimizer.step()               # 업데이트를 계속 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "aa129258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7090], requires_grad=True)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W # 업데이트가 되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "567d3704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6515], requires_grad=True)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B # 정답은 0이고 가까워지고 있다. \n",
    "  # 여기서 코스트 단계로 다시 가야한다.  이게 모델의 훈련 절차이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0094d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 이걸 반복하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "339c1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8666667938232422 0.800000011920929 18.66666603088379\n",
      "100 1.9722299575805664 0.06312811374664307 0.0006002071313560009\n",
      "200 1.9975632429122925 0.005539316684007645 4.621344942279393e-06\n",
      "300 1.9997862577438354 0.0004860826884396374 3.557685701593982e-08\n",
      "400 1.9999812841415405 4.265585448592901e-05 2.739284354902338e-10\n",
      "500 1.9999983310699463 3.698257842188468e-06 1.9137285072606813e-12\n",
      "600 1.9999998807907104 4.080832525232836e-07 1.8947806851624636e-14\n",
      "700 2.0 1.0608626155317324e-07 0.0\n",
      "800 2.0 1.0608626155317324e-07 0.0\n",
      "900 2.0 1.0608626155317324e-07 0.0\n",
      "1000 2.0 1.0608626155317324e-07 0.0\n",
      "1100 2.0 1.0608626155317324e-07 0.0\n",
      "1200 2.0 1.0608626155317324e-07 0.0\n",
      "1300 2.0 1.0608626155317324e-07 0.0\n",
      "1400 2.0 1.0608626155317324e-07 0.0\n",
      "1500 2.0 1.0608626155317324e-07 0.0\n",
      "1600 2.0 1.0608626155317324e-07 0.0\n",
      "1700 2.0 1.0608626155317324e-07 0.0\n",
      "1800 2.0 1.0608626155317324e-07 0.0\n",
      "1900 2.0 1.0608626155317324e-07 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    hx = W * x_train + B\n",
    "    cost = torch.mean((hx - y_train)**2) \n",
    "    optimizer = optim.SGD([W,B], lr=0.01)  # 사실 이건 안에 있을 필요는 없다. \n",
    "    optimizer.zero_grad()      \n",
    "    cost.backward()            \n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print(epoch,W.item(),B.item(),cost.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "32908dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7755e-10, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "37204a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999947471260384"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.item()*5+B.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ba1b21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미분계산을 자동으로 해서 반영하는 함수인 백워드 함수를 볼 수 있었다.\n",
    "w = torch.tensor(2.0, requires_grad=True) # 기울기를 구해서 저장하겠다는 의미이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "58688eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b9148ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "d31ae719",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 2*y+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "0a24fb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "d5bcf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward() # 미분을 한 상황이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "6813fde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad#z수식을 w로 미분한 값은 얼마인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "5ddebc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x변수가 3개가 있다고 해보자. 각각의 데이터에 대해 가중치가 붙을 것이다. \n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 문제를 보면 연립방정식을 풀게 될 듯 하다. \n",
    "# 수능점수 예측값을 도출하는 수식을 얻고자 한다. \n",
    "# 우리가 만든 모델을 가지고 앞으로 몇 점을 받을 것인지를 예측하고자 한다. \n",
    "# 데이터셋으로부터 만든 모델이 가지고 있는 웨이트와 바이어스를 곱하고 더해서 예측값을 도출하고자 하는게 목표일 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "26596f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape # 5행 1열이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "5295a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.zeros(1,requires_grad = True)\n",
    "W2 = torch.zeros(1,requires_grad = True)\n",
    "W3 = torch.zeros(1,requires_grad = True)\n",
    "B  = torch.zeros(1,requires_grad = True)\n",
    "# 초기화 작업이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "07baafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.29401201009750366 0.2935999929904938 0.2973800003528595 0.0034199999645352364 29661.80078125\n",
      "100 0.6735065579414368 0.6609680652618408 0.6762314438819885 0.007919806987047195 1.5636341571807861\n",
      "200 0.6789458990097046 0.6549617052078247 0.676784336566925 0.008070035837590694 1.4976074695587158\n",
      "300 0.6842513084411621 0.649121880531311 0.6773051619529724 0.008219091221690178 1.4350258111953735\n",
      "400 0.6894262433052063 0.6434438228607178 0.6777952909469604 0.00836699828505516 1.375730276107788\n",
      "500 0.6944740414619446 0.6379234194755554 0.6782552599906921 0.008513780310750008 1.3195109367370605\n",
      "600 0.6993983387947083 0.6325562000274658 0.6786861419677734 0.008659474551677704 1.2662218809127808\n",
      "700 0.7042022347450256 0.6273384094238281 0.6790884137153625 0.008804094977676868 1.2156964540481567\n",
      "800 0.7088890075683594 0.622265636920929 0.6794635057449341 0.008947668597102165 1.1678179502487183\n",
      "900 0.7134621739387512 0.6173338294029236 0.6798113584518433 0.009090210311114788 1.1224288940429688\n",
      "1000 0.7179242968559265 0.6125394701957703 0.6801334619522095 0.009231756441295147 1.0793778896331787\n",
      "1100 0.7222781181335449 0.6078792810440063 0.6804301738739014 0.009372316300868988 1.0385843515396118\n",
      "1200 0.7265268564224243 0.6033490300178528 0.6807023882865906 0.009511923417448997 0.999893844127655\n",
      "1300 0.7306730151176453 0.5989454984664917 0.6809508800506592 0.00965059082955122 0.9632169604301453\n",
      "1400 0.7347195744514465 0.5946652293205261 0.6811760663986206 0.00978833343833685 0.9284208416938782\n",
      "1500 0.738669216632843 0.5905049443244934 0.6813786625862122 0.009925177320837975 0.8954533338546753\n",
      "1600 0.7425243258476257 0.5864613652229309 0.6815593838691711 0.010061148554086685 0.8641611337661743\n",
      "1700 0.7462873458862305 0.5825314521789551 0.6817188262939453 0.010196257382631302 0.8345034718513489\n",
      "1800 0.749960720539093 0.5787121653556824 0.6818577647209167 0.010330503806471825 0.8063748478889465\n",
      "1900 0.753546953201294 0.575000524520874 0.6819765567779541 0.010463932529091835 0.7796962857246399\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([W1,W2,W3,B], lr=0.00001) # 안에 있을 필요없어서 바깥으로 뺐다. 0.01에서 0.1까지 부여하는게 일반적이다.\n",
    "for epoch in range(2000):\n",
    "    hx = W1 * x1_train + W2 * x2_train + W3 * x3_train + B\n",
    "    cost = torch.mean((hx - y_train)**2) \n",
    "    optimizer.zero_grad()      \n",
    "    cost.backward()            \n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print(epoch,W1.item(),W2.item(),W3.item(),B.item(),cost.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "e32a9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뭔가 매우 이상하게 이루어졌다. 이것의 문제는 발산해버린 경우이다. \n",
    "# 코스트가 계속 올라가다가 아무것도 나오지 않는다. lr값이 너무 큰 경우다. \n",
    "# 또는 입력데이터에 대해 편차가 심한 경우이다. 정규화나 표준화가 이루어지지 않은 경우에 이렇게 된다. \n",
    "x1_train = torch.FloatTensor([[0.73], [0.93], [0.89], [0.96], [0.73]])\n",
    "x2_train = torch.FloatTensor([[0.80], [0.88], [0.91], [0.98], [0.66]])\n",
    "x3_train = torch.FloatTensor([[0.75], [0.93], [0.90], [1.00], [0.70]])\n",
    "y_train = torch.FloatTensor([[1.52], [1.85], [1.80], [1.96], [1.42]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1a0b06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.zeros(1,requires_grad = True)\n",
    "W2 = torch.zeros(1,requires_grad = True)\n",
    "W3 = torch.zeros(1,requires_grad = True)\n",
    "B  = torch.zeros(1,requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "1fc38e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.029401199892163277 0.029360000044107437 0.02973800152540207 0.03420000150799751 2.9661800861358643\n",
      "100 0.46306613087654114 0.46245095133781433 0.4696241617202759 0.5268245935440063 0.0035478007048368454\n",
      "200 0.4669475853443146 0.46634650230407715 0.4749852418899536 0.5177428126335144 0.0034022568725049496\n",
      "300 0.47018158435821533 0.4695737063884735 0.4796554744243622 0.5081755518913269 0.0032679885625839233\n",
      "400 0.47335726022720337 0.47272154688835144 0.48423129320144653 0.4988046884536743 0.0031391982920467854\n",
      "500 0.47647643089294434 0.47579237818717957 0.48871535062789917 0.4896276295185089 0.003015674650669098\n",
      "600 0.47954025864601135 0.4787876307964325 0.4931096136569977 0.480640172958374 0.0028971899300813675\n",
      "700 0.48254990577697754 0.48170921206474304 0.4974158704280853 0.4718383550643921 0.0027835420332849026\n",
      "800 0.4855063855648041 0.4845585227012634 0.5016360282897949 0.4632183611392975 0.0026745288632810116\n",
      "900 0.4884108006954193 0.4873371124267578 0.5057717561721802 0.45477643609046936 0.0025699627585709095\n",
      "1000 0.4912642538547516 0.49004653096199036 0.5098247528076172 0.44650885462760925 0.0024696658365428448\n",
      "1100 0.4940677583217621 0.49268823862075806 0.513796865940094 0.4384121000766754 0.002373457420617342\n",
      "1200 0.496822327375412 0.4952635169029236 0.5176897644996643 0.4304824769496918 0.0022811726666986942\n",
      "1300 0.4995289742946625 0.4977739155292511 0.5215049386024475 0.4227166175842285 0.0021926481276750565\n",
      "1400 0.5021885633468628 0.5002207159996033 0.5252440571784973 0.41511115431785583 0.0021077380515635014\n",
      "1500 0.5048021674156189 0.5026053786277771 0.5289088487625122 0.4076627194881439 0.0020262799225747585\n",
      "1600 0.50737065076828 0.5049291253089905 0.532500684261322 0.4003680646419525 0.0019481431227177382\n",
      "1700 0.509894847869873 0.5071931481361389 0.5360209941864014 0.3932243287563324 0.0018731874879449606\n",
      "1800 0.5123758912086487 0.5093989968299866 0.539471447467804 0.38622766733169556 0.0018012862419709563\n",
      "1900 0.514814555644989 0.511547863483429 0.5428533554077148 0.3793754577636719 0.0017323065549135208\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([W1,W2,W3,B], lr=0.01) # 안에 있을 필요없어서 바깥으로 뺐다. 0.01에서 0.1까지 부여하는게 일반적이다.\n",
    "for epoch in range(2000):\n",
    "    hx = W1 * x1_train + W2 * x2_train + W3 * x3_train + B\n",
    "    cost = torch.mean((hx - y_train)**2) \n",
    "    optimizer.zero_grad()      \n",
    "    cost.backward()            \n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print(epoch,W1.item(),W2.item(),W3.item(),B.item(),cost.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "af1cfde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코스트가 0인 경우는 거의 존재하지 않는다. 선형모델이 아닌 이상 나오지 않는다. \n",
    "# 팁으로 0.00001은 1e-5로 표시 가능하다. \n",
    "# 문제는 표준화하면 뭔가 답이 이상해진다. 그냥 0을 5개 붙이는게 더 정확한 듯 하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "3d6493c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.1425551418215"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.item()*73 + W2.item()*80 + W3.item()*75 + B.item() # 쉽지않다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "9825e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "5f62c5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape) \n",
    "# 먼저 연산을 하려면 행열을 맞춰야 한다. \n",
    "# W1,W2,W3를 하나로 합쳐서 행렬로 나타내보는 것도 방법일 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "0c112055",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3,1),requires_grad = True) # 우리는 W를 한꺼번에 실행시키고 싶다. \n",
    "B = torch.zeros(1,requires_grad = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "4d996d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([W,B],lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "bceb9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9537.6943359375\n",
      "100 5.752121448516846\n",
      "200 5.510031700134277\n",
      "300 5.2793989181518555\n",
      "400 5.059759616851807\n",
      "500 4.850369930267334\n",
      "600 4.650723457336426\n",
      "700 4.460408687591553\n",
      "800 4.278825759887695\n",
      "900 4.105560779571533\n",
      "1000 3.940225124359131\n",
      "1100 3.782344102859497\n",
      "1200 3.6315715312957764\n",
      "1300 3.4875869750976562\n",
      "1400 3.3499629497528076\n",
      "1500 3.218451738357544\n",
      "1600 3.092745304107666\n",
      "1700 2.9725329875946045\n",
      "1800 2.8575236797332764\n",
      "1900 2.7475745677948\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    hx=x_train.matmul(W) + B\n",
    "    cost=torch.mean((hx - y_train)**2)\n",
    "    optimizer.zero_grad()#미분을 해서 구한 기울기를 0으로 초기화해줌\n",
    "    cost.backward() #W, b에 대한 기울기가 계산\n",
    "    optimizer.step()#W,b에 대한 업데이트\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, cost.item())\n",
    "# 코스트는 떨어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "703e88cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7106], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "46e9ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 모델을 구현해보자. \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "57865d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x268b42ffb30>"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "42eafea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "ddcf0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1) #입력차원과 출력차원을 기재하면 된다. 입력변수가 1개고 출력변수도 1개이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "0131b103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.9414]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.5997], requires_grad=True)]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters()) # w와 b값을 볼 수 있다. 위가 w값, 밑이 b값이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "3a9de53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)  # 사실상 변함이 없다. 아담대신 sgd고 퍼러미터를 직접 설정하는것 뿐이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "0d7008cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 33.67978286743164\n",
      "100 0.223159059882164\n",
      "200 0.1378987580537796\n",
      "300 0.08521304279565811\n",
      "400 0.05265649035573006\n",
      "500 0.03253853693604469\n",
      "600 0.020106827840209007\n",
      "700 0.012424829415977001\n",
      "800 0.00767778092995286\n",
      "900 0.004744391422718763\n",
      "1000 0.002931751310825348\n",
      "1100 0.001811650930903852\n",
      "1200 0.0011194882681593299\n",
      "1300 0.0006917758728377521\n",
      "1400 0.0004274678649380803\n",
      "1500 0.0002641582686919719\n",
      "1600 0.0001632305938983336\n",
      "1700 0.00010086849943036214\n",
      "1800 6.232853775145486e-05\n",
      "1900 3.8514306652359664e-05\n"
     ]
    }
   ],
   "source": [
    "# hx부의 구문이 바뀔 것이다. \n",
    "for epoch in range(2000):\n",
    "    hx = model(x_train)       # 모델값 자체다.\n",
    "    cost = F.mse_loss(hx,y_train)         # 아까 한 mse이다. \n",
    "    optimizer.zero_grad()#미분을 해서 구한 기울기를 0으로 초기화해줌\n",
    "    cost.backward() #W, b에 대한 기울기가 계산\n",
    "    optimizer.step()#W,b에 대한 업데이트\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "34daaa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.9943]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0129], requires_grad=True)]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())  # 값이 확실히 바뀌었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "7c959dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var =  torch.FloatTensor([[4.0]]) # 문제를 내보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "91e158f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.9902]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_var) # 답이 나왔다. 이것은 predict와 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "10fdcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "9ffc0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "f26a39a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1188,  0.2937,  0.0803]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0707], requires_grad=True)]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "82f2f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "e0c9d94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8999069333076477\n",
      "100 0.8697694540023804\n",
      "200 0.8411844372749329\n",
      "300 0.8140530586242676\n",
      "400 0.7883228063583374\n",
      "500 0.7639040350914001\n",
      "600 0.7407382726669312\n",
      "700 0.7187463045120239\n",
      "800 0.6978789567947388\n",
      "900 0.6780833005905151\n",
      "1000 0.6592813730239868\n",
      "1100 0.6414272785186768\n",
      "1200 0.6244879961013794\n",
      "1300 0.6083956956863403\n",
      "1400 0.5931113958358765\n",
      "1500 0.5786016583442688\n",
      "1600 0.5648104548454285\n",
      "1700 0.5517212152481079\n",
      "1800 0.5392765402793884\n",
      "1900 0.5274502635002136\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    hx = model(x_train)       \n",
    "    cost = F.mse_loss(hx,y_train)         \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward() \n",
    "    optimizer.step()\n",
    "    if epoch%100 ==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "e6786c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var =  torch.FloatTensor([[90,90,90]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "8ea5959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[180.9370]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_var) # 비슷하게 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "a53b011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.7909, 0.5203, 0.6999]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0545], requires_grad=True)]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())  # 퍼러미터도 꽤 잘 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c30879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 단순 직선이 아니라 곡선형태의 모델이 만들어진다면 n차 방정식과 같은 모양새를 보일 것이다. \n",
    "# 이걸 클래스로 구현할 수 있어야 실전에 참여할 수 있다. \n",
    "# bert기반의 모델은 파이토치를 쓰는 경우가 많다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
